{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Axcq0FXj5eF",
        "outputId": "b066878d-8c55-46d1-e2aa-cae1f72bbfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------\n",
            "\n",
            "Ananda Rauf Maududi\n",
            "Strata 1 / Sarjana Komputer\n",
            "Universitas Bina Sarana Informatika\n",
            "Junior Python Programmer\n",
            "PT Kalanara Group Indonesia\n",
            "-------------------------------------------------------------------------------------------\n",
            "\n",
            "Found 401 images belonging to 3 classes.\n",
            "Found 401 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 13/100 [==>...........................] - ETA: 17s - loss: -248.1658 - accuracy: 0.0524"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 6s 38ms/step - loss: -248.1658 - accuracy: 0.0524 - val_loss: -1332.2747 - val_accuracy: 0.0474 - lr: 0.0010\n",
            "13/13 [==============================] - 1s 85ms/step - loss: -1332.2748 - accuracy: 0.0474\n",
            "Validation Loss: -1332.2747802734375, Validation Accuracy: 4.74%\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Prediction result: Kertas\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Data Diri\n",
        "print(\"-------------------------------------------------------------------------------------------\\n\")\n",
        "nama = \"Ananda Rauf Maududi\"\n",
        "school_title = \"Strata 1 / Sarjana Komputer\"\n",
        "school = \"Universitas Bina Sarana Informatika\"\n",
        "job_title = \"Junior Python Programmer\"\n",
        "work_on = \"PT Kalanara Group Indonesia\"\n",
        "print(nama)\n",
        "print(school_title)\n",
        "print(school)\n",
        "print(job_title)\n",
        "print(work_on)\n",
        "print(\"-------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "# Direktori dataset\n",
        "base_dir = '/content/dataset'\n",
        "train_dir = os.path.join(base_dir, 'train_validation')\n",
        "validation_dir = os.path.join(base_dir, 'train_validation')\n",
        "\n",
        "# Augmentasi Gambar menggunakan ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Membangun Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Kompilasi Model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
        "\n",
        "# Pelatihan Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,  # asumsikan kita memiliki 2000 gambar, batch_size=20\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,  # asumsikan kita memiliki 1000 gambar validasi, batch_size=20\n",
        "    callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Menyimpan Riwayat Pelatihan\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.to_csv('/content/Save_Dataset/training_history.csv', index=False)\n",
        "\n",
        "# Evaluasi Model\n",
        "eval_result = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {eval_result[0]}, Validation Accuracy: {eval_result[1]*100:.2f}%')\n",
        "\n",
        "# Fungsi Prediksi Gambar yang Diunggah\n",
        "def predict_uploaded_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = 'Kertas' if predictions[0] > 0.5 else 'Bukan Kertas'\n",
        "    return predicted_class\n",
        "\n",
        "# Prediksi Gambar\n",
        "uploaded_image_path = '/content/gambar_upload/Kertas.png'\n",
        "prediction = predict_uploaded_image(uploaded_image_path)\n",
        "print(f'Prediction result: {prediction}')"
      ]
    }
  ]
}